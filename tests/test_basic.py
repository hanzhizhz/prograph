#!/usr/bin/env python3
"""
ProGraph åŸºç¡€æµ‹è¯•
éªŒè¯å„ä¸ªæ¨¡å—çš„åŸºæœ¬åŠŸèƒ½
"""

import sys
from pathlib import Path

# æ·»åŠ  src è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.config import ModelConfig, GraphConfig, RetrievalConfig


def test_config():
    """æµ‹è¯•é…ç½®åŠ è½½"""
    print("=" * 60)
    print("æµ‹è¯• 1: é…ç½®ç³»ç»Ÿ")
    print("=" * 60)

    # æµ‹è¯• YAML åŠ è½½
    model_config = ModelConfig.from_yaml("config.yaml")
    print(f"âœ“ æ¨¡å‹é…ç½®åŠ è½½æˆåŠŸ")
    print(f"  - vLLM æ¨¡å‹: {model_config.vllm.model_path}")
    print(f"  - LLM API: {model_config.llm.base_url}")

    graph_config = GraphConfig.from_yaml("config.yaml")
    print(f"âœ“ å›¾é…ç½®åŠ è½½æˆåŠŸ")
    print(f"  - å‘½é¢˜æå–æ¸©åº¦: {graph_config.proposition_extraction.temperature}")

    retrieval_config = RetrievalConfig.from_yaml("config.yaml")
    print(f"âœ“ æ£€ç´¢é…ç½®åŠ è½½æˆåŠŸ")
    print(f"  - æœ€å¤§æ·±åº¦: {retrieval_config.max_path_depth}")
    print(f"  - Beam width: {retrieval_config.beam_width}")

    print("\né…ç½®ç³»ç»Ÿæµ‹è¯•é€šè¿‡ï¼\n")
    return True


def test_document_loader():
    """æµ‹è¯•æ–‡æ¡£åŠ è½½å™¨"""
    print("=" * 60)
    print("æµ‹è¯• 2: æ–‡æ¡£åŠ è½½å™¨")
    print("=" * 60)

    from src.proposition_graph import DocumentLoader

    loader = DocumentLoader()
    documents = loader.load("dataset/test/test_docs.json")

    print(f"âœ“ åŠ è½½äº† {len(documents)} ä¸ªæ–‡æ¡£")

    for doc in documents:
        print(f"  - {doc.title}: {len(doc.content)} ä¸ªå¥å­")

    print("\næ–‡æ¡£åŠ è½½å™¨æµ‹è¯•é€šè¿‡ï¼\n")
    return True


def test_proposition_extractor():
    """æµ‹è¯•å‘½é¢˜æå–å™¨ï¼ˆmockï¼‰"""
    print("=" * 60)
    print("æµ‹è¯• 3: å‘½é¢˜æå–å™¨ï¼ˆMockï¼‰")
    print("=" * 60)

    from src.proposition_graph import PropositionExtractor
    from src.llm.base import LLMResponse
    import asyncio

    # åˆ›å»º mock LLM
    class MockLLM:
        async def generate(self, prompt, **kwargs):
            # è¿”å›æ¨¡æ‹Ÿçš„ JSON å“åº”
            return LLMResponse(
                text='''```json
[
  "The entity is mentioned in the text.",
  "This is a test proposition."
]
```''',
                prompt_tokens=100,
                completion_tokens=50,
                total_tokens=150,
                model="mock"
            )

    mock_llm = MockLLM()
    extractor = PropositionExtractor(llm=mock_llm)

    # æµ‹è¯•å¼‚æ­¥
    async def test():
        propositions = await extractor.extract_from_sentence(
            "Barack Obama was born in Hawaii.",
            sent_idx=0,
            doc_id="test"
        )
        return propositions

    propositions = asyncio.run(test())
    print(f"âœ“ æå–äº† {len(propositions)} ä¸ªå‘½é¢˜")
    for prop in propositions:
        print(f"  - {prop.text}")

    print("\nå‘½é¢˜æå–å™¨æµ‹è¯•é€šè¿‡ï¼\n")
    return True


def test_graph_builder():
    """æµ‹è¯•å›¾æ„å»ºå™¨ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    print("=" * 60)
    print("æµ‹è¯• 4: å›¾æ„å»ºå™¨ï¼ˆç®€åŒ–ï¼‰")
    print("=" * 60)

    import networkx as nx

    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•å›¾
    graph = nx.DiGraph()

    # æ·»åŠ å‘½é¢˜èŠ‚ç‚¹
    graph.add_node("prop1", node_type="proposition", text="Barack Obama was born in Hawaii.", doc_id="test")
    graph.add_node("prop2", node_type="proposition", text="He served as the 44th President.", doc_id="test")

    # æ·»åŠ å®ä½“èŠ‚ç‚¹
    graph.add_node("ent1", node_type="entity", text="Barack Obama", entity_type="PERSON", doc_id="test")
    graph.add_node("ent2", node_type="entity", text="Hawaii", entity_type="LOCATION", doc_id="test")

    # æ·»åŠ è¾¹
    graph.add_edge("prop1", "ent1", edge_type="MENTIONS_ENTITY")
    graph.add_edge("prop1", "ent2", edge_type="MENTIONS_ENTITY")

    print(f"âœ“ åˆ›å»ºæµ‹è¯•å›¾")
    print(f"  - èŠ‚ç‚¹æ•°: {graph.number_of_nodes()}")
    print(f"  - è¾¹æ•°: {graph.number_of_edges()}")

    # ä¿å­˜æµ‹è¯•
    import pickle
    from pathlib import Path

    output_dir = Path("output/test")
    output_dir.mkdir(parents=True, exist_ok=True)

    with open(output_dir / "test_graph.pkl", "wb") as f:
        pickle.dump(graph, f)

    print(f"âœ“ æµ‹è¯•å›¾å·²ä¿å­˜åˆ° output/test/test_graph.pkl")

    print("\nå›¾æ„å»ºå™¨æµ‹è¯•é€šè¿‡ï¼\n")
    return True


def test_prompt_templates():
    """æµ‹è¯•æç¤ºè¯æ¨¡æ¿"""
    print("=" * 60)
    print("æµ‹è¯• 5: æç¤ºè¯æ¨¡æ¿")
    print("=" * 60)

    from src.proposition_graph import prompts

    # æµ‹è¯•å‘½é¢˜æå–æç¤ºè¯
    prop_prompt = prompts.get_proposition_extraction_prompt("Barack Obama was born in Hawaii.")
    print(f"âœ“ å‘½é¢˜æå–æç¤ºè¯é•¿åº¦: {len(prop_prompt)} å­—ç¬¦")

    # æµ‹è¯•å®ä½“æå–æç¤ºè¯
    entity_prompt = prompts.get_entity_extraction_prompt("Barack Obama was born in Hawaii.")
    print(f"âœ“ å®ä½“æå–æç¤ºè¯é•¿åº¦: {len(entity_prompt)} å­—ç¬¦")

    # æµ‹è¯• RST åˆ†ææç¤ºè¯
    rst_prompt = prompts.get_rst_analysis_prompt(
        "Barack Obama was born in Hawaii.",
        "He served as the 44th President."
    )
    print(f"âœ“ RST åˆ†ææç¤ºè¯é•¿åº¦: {len(rst_prompt)} å­—ç¬¦")

    # æµ‹è¯•æ„å›¾è¯†åˆ«æç¤ºè¯
    intent_prompt = prompts.get_intent_recognition_prompt(
        "Where was Barack Obama born?",
        "prop1 -> prop2",
        "Barack Obama, Hawaii"
    )
    print(f"âœ“ æ„å›¾è¯†åˆ«æç¤ºè¯é•¿åº¦: {len(intent_prompt)} å­—ç¬¦")

    print("\næç¤ºè¯æ¨¡æ¿æµ‹è¯•é€šè¿‡ï¼\n")
    return True


def test_path_scorer_formula():
    """æµ‹è¯•è·¯å¾„è¯„åˆ†å…¬å¼"""
    print("=" * 60)
    print("æµ‹è¯• 7: è·¯å¾„è¯„åˆ†å…¬å¼")
    print("=" * 60)

    import numpy as np

    # æµ‹è¯•ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—
    vec1 = np.array([1.0, 0.0, 0.0])
    vec2 = np.array([1.0, 0.0, 0.0])
    vec3 = np.array([0.0, 1.0, 0.0])

    # ç›¸åŒå‘é‡
    sim = np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))
    print(f"âœ“ ç›¸åŒå‘é‡ç›¸ä¼¼åº¦: {sim} (åº”ä¸º 1.0)")

    # æ­£äº¤å‘é‡
    sim = np.dot(vec1, vec3) / (np.linalg.norm(vec1) * np.linalg.norm(vec3))
    print(f"âœ“ æ­£äº¤å‘é‡ç›¸ä¼¼åº¦: {sim} (åº”ä¸º 0.0)")

    # æµ‹è¯•æ¡¥æ¥åˆ†æ•°å…¬å¼
    mentioned_entities = {"ent1", "ent2", "ent3"}
    visited_entities = {"ent1"}

    novel_entities = mentioned_entities - visited_entities
    bridge_score = len(novel_entities) / len(mentioned_entities)
    print(f"\nâœ“ æ¡¥æ¥åˆ†æ•°è®¡ç®—:")
    print(f"  - æåŠå®ä½“: {mentioned_entities}")
    print(f"  - å·²è®¿é—®å®ä½“: {visited_entities}")
    print(f"  - æ–°å®ä½“: {novel_entities}")
    print(f"  - æ¡¥æ¥åˆ†æ•°: {bridge_score} (åº”ä¸º 0.67)")

    print("\nè·¯å¾„è¯„åˆ†å…¬å¼æµ‹è¯•é€šè¿‡ï¼\n")
    return True


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n")
    print("*" * 60)
    print("*" + " " * 58 + "*")
    print("*" + "  ProGraph åŸºç¡€æµ‹è¯•".center(56) + "*")
    print("*" + " " * 58 + "*")
    print("*" * 60)
    print("\n")

    tests = [
        ("é…ç½®ç³»ç»Ÿ", test_config),
        ("æ–‡æ¡£åŠ è½½å™¨", test_document_loader),
        ("å‘½é¢˜æå–å™¨", test_proposition_extractor),
        ("å›¾æ„å»ºå™¨", test_graph_builder),
        ("æç¤ºè¯æ¨¡æ¿", test_prompt_templates),
        ("è·¯å¾„è¯„åˆ†å…¬å¼", test_path_scorer_formula),
    ]

    results = []

    for name, test_func in tests:
        try:
            result = test_func()
            results.append((name, result))
        except Exception as e:
            print(f"âœ— {name} æµ‹è¯•å¤±è´¥: {e}\n")
            results.append((name, False))

    # æ€»ç»“
    print("=" * 60)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 60)

    passed = sum(1 for _, result in results if result)
    total = len(results)

    for name, result in results:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"  {name}: {status}")

    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")

    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print(f"\nâš ï¸  {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")

    return passed == total


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
